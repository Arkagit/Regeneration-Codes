betas <- matrix(0, nrow = nsim, ncol = 3)
z <- matrix(0, nrow = nsim, ncol = m)
# starting value of beta are the mle estaimtes
z.curr <- numeric(length = m)
fit <- glm(y ~ -1 + x, family = binomial(link = "probit") )
beta.curr <- coef(fit)
# Needed for the truncated normal
lower <- numeric(length = m)
upper <- numeric(length = m)
for(i in 1:m)
{
if(y[i] == 0)
{
lower[i] <- -Inf
upper[i] <- 0
}else
{
lower[i] <- 0
upper[i] <- Inf
}
}
# Doing non-repetitive calculations outside
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
for(i in 1:nsim)
{
z.curr <- rtruncnorm(m, a = lower, b = upper, mean = x%*%beta.curr, sd = 1)
beta.curr <- inv.xtx %*% t(x) %*% z.curr + mvrnorm(n=1,c(0,0,0),inv.xtx)
betas[i, ] <- beta.curr
z[i, ] <- z.curr
}
return(list("beta" = betas, "z" = z))
}
###############################################################################
##Calculation of
init <- 2e4
out.2e4 <- probit_gibbs(dat = dat, nsim = init)
z.star <- colMeans(out.2e4$z[1:init, ])
beta.bar <- colMeans(out.2e4$beta[1:init, ])
s <- apply(out.2e4$beta[1:init, ], 2, sd)
c <- beta.bar - .09*s
d <- beta.bar + .09*s
nsim <- 1e6
ac.out.1e6 <- probit_gibbs(dat = dat, nsim = nsim)
eta <- numeric(length = nsim)
x <- dat[, -4]
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
inv.xtx.tx <- solve(xtx)%*%t(x)
density_mv = function(input, mu, V){
lngt = length(input)
obj = exp(-0.5*t(input - mu)%*%solve(V)%*%(input - mu))/sqrt(det(V)*((2*pi)^(lngt)))
return(obj)
}
density_tn = function(inp, betaj){
for (t in 1:55) {
obj1 = 1
if(inp[t] > 0){
obj1 = obj1*dtruncnorm(inp[t], a = 0, b = Inf, mean = (x%*%betaj)[t], 1)
}else{
obj1 = obj1*dtruncnorm(inp[t], a = -Inf, b = 0, mean = (x%*%betaj)[t], 1)
}
}
return(obj1)
}
etaj <- function(betaj0, zj0, betaj2, zj2){
ret <- 0
t.starj <- t(zj0 - z.star)%*%x
if(prod((betaj2 < d & betaj2 > c)) == 1)
{
ret <- sum(t.starj*(c* (t.starj > 0) + d * (t.starj < 0))) - 0.5*t(zj0)%*%x%*%inv.xtx%*%t(x)%*%zj0 + 0.5*t(z.star)%*%x%*%inv.xtx%*%t(x)%*%z.star+ log(density_mv(betaj2,inv.xtx.tx%*%z.star,inv.xtx)) + sum(log(density_tn(zj2, betaj2)))
ret <- ret - log(density_mv(betaj2,inv.xtx.tx%*%zj0,inv.xtx) + density_mv(betaj2,inv.xtx.tx%*%zj0,inv.xtx)*prod(density_tn(zj2,betaj2)) +  density_mv(betaj2,inv.xtx.tx%*%zj2,inv.xtx)*prod(density_tn(zj2,betaj0)) + prod(density_tn(zj2,betaj0)))
ret <- exp(ret)
}else{
ret <- 0
}
return(ret)
}
for(j in 1:(nsim-2))
{
betaj2 <- ac.out.1e6$beta[j+2,]
zj2 <- ac.out.1e6$z[j+2,]
betaj0 <- ac.out.1e6$beta[j,]
zj0 <- ac.out.1e6$z[j,]
eta[j] <- etaj(betaj0, zj0, betaj2, zj2)
}
# Number of times chain is in the small set
sum(eta > 0)
pos_eta = eta[(eta > 0) == TRUE]
length(pos_eta)
sum=0
for (i in 1:1850) {
sum = sum + rbinom(1,1,pos_eta[i])
}
sum
set.seed(4321)
## Entering Data
x1.dummy <- seq(-3, 1.5, by = 0.5)
x2.dummy <- seq(0, 2, by = 0.5)
## The two column covariates
x1 <- rep(x1.dummy, each = length(x2.dummy))
x2 <- rep(x2.dummy, times = length(x1.dummy))
# Total number of cases. Follow the rows in the image above
n <- c(1, rep(0,4), 3, rep(0,4), 7, rep(0,3),
1, 6, 1, rep(0,3), 6,1,1,0,1,4,0,0,1,0,3,
0,1,1,0,4,0,1,1,1,1,0,1,1,4,1,0,0,2,0)
# Number of Lupus cases, foow the numerator across rows in the image
y <- c(0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,3,1,1,1,1,1,1,4,1,2)
# Following code makes a data matrix of all cases and lupus cases removing
# the combinations of covariates with noncases
dat.binom <- cbind(n,rep(1, 50), x1, x2)
dat.binom <- dat.binom[!(dat.binom[,1] == 0), ]
dat.binom <- cbind(dat.binom,y)
# Following code essentially converts binomial data to bernoulli data
dummy <- sapply(1:length(y), function(x) matrix(rep(dat.binom[x, -1], dat.binom[x,1]),nrow = dat.binom[x,1], byrow = TRUE) )
dat <- do.call(rbind, dummy)
dat[(dat[,4] >0),4] <- 1
# Fixing a mistake
dat[39,4] <- 0
colnames(dat) <- c("intercept", "x1", "x2", "y")
dim(dat)
x <- dat[, -4]
A =  t(x)%*%x
B = solve(A)
A = solve(B)
####################################################################################
####################################################################################
library(MASS)
library(Matrix)
library(truncnorm)
## AC for Bayesian probit regression
probit_gibbs <- function(dat, nsim)
{
# Separate covariates and response
x <- dat[, -4]
y <- dat[, 4]
m <- length(y)
#return objects
betas <- matrix(0, nrow = nsim, ncol = 3)
z <- matrix(0, nrow = nsim, ncol = m)
# starting value of beta are the mle estaimtes
z.curr <- numeric(length = m)
fit <- glm(y ~ -1 + x, family = binomial(link = "probit") )
beta.curr <- coef(fit)
# Needed for the truncated normal
lower <- numeric(length = m)
upper <- numeric(length = m)
for(i in 1:m)
{
if(y[i] == 0)
{
lower[i] <- -Inf
upper[i] <- 0
}else
{
lower[i] <- 0
upper[i] <- Inf
}
}
# Doing non-repetitive calculations outside
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
for(i in 1:nsim)
{
z.curr <- rtruncnorm(m, a = lower, b = upper, mean = x%*%beta.curr, sd = 1)
beta.curr <- inv.xtx %*% t(x) %*% z.curr + mvrnorm(n=1,c(0,0,0),inv.xtx)
betas[i, ] <- beta.curr
z[i, ] <- z.curr
}
return(list("beta" = betas, "z" = z))
}
###############################################################################
##Calculation of
init <- 2e4
out.2e4 <- probit_gibbs(dat = dat, nsim = init)
z.star <- colMeans(out.2e4$z[1:init, ])
beta.bar <- colMeans(out.2e4$beta[1:init, ])
s <- apply(out.2e4$beta[1:init, ], 2, sd)
c <- beta.bar - .09*s
d <- beta.bar + .09*s
nsim <- 1e6
ac.out.1e6 <- probit_gibbs(dat = dat, nsim = nsim)
eta <- numeric(length = nsim)
x <- dat[, -4]
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
inv.xtx.tx <- solve(xtx)%*%t(x)
density_mv = function(input, mu, V){
lngt = length(input)
obj = exp(-0.5*t(input - mu)%*%solve(V)%*%(input - mu))/sqrt(det(V)*((2*pi)^(lngt)))
return(obj)
}
density_tn = function(inp, betaj){
for (t in 1:55) {
obj1 = 1
if(inp[t] > 0){
obj1 = obj1*dtruncnorm(inp[t], a = 0, b = Inf, mean = (x%*%betaj)[t], 1)
}else{
obj1 = obj1*dtruncnorm(inp[t], a = -Inf, b = 0, mean = (x%*%betaj)[t], 1)
}
}
return(obj1)
}
etaj <- function(betaj0, zj0, betaj2, zj2){
ret <- 0
t.starj <- t(zj0 - z.star)%*%x
if(prod((betaj2 < d & betaj2 > c)) == 1)
{
ret <- sum(t.starj*(c* (t.starj > 0) + d * (t.starj < 0))) - 0.5*t(zj0)%*%x%*%inv.xtx%*%t(x)%*%zj0 + 0.5*t(z.star)%*%x%*%inv.xtx%*%t(x)%*%z.star+ log(density_mv(betaj2,inv.xtx.tx%*%z.star,inv.xtx)) + sum(log(density_tn(zj2, betaj2)))
ret <- ret - log(density_mv(betaj2,inv.xtx.tx%*%zj0,inv.xtx) + density_mv(betaj2,inv.xtx.tx%*%zj0,inv.xtx)*prod(density_tn(zj2,betaj2)) +  density_mv(betaj2,inv.xtx.tx%*%zj2,inv.xtx)*prod(density_tn(zj2,betaj0)) + prod(density_tn(zj2,betaj0)))
ret <- exp(ret)
}else{
ret <- 0
}
return(ret)
}
for(j in 1:(nsim-2))
{
betaj2 <- ac.out.1e6$beta[j+2,]
zj2 <- ac.out.1e6$z[j+2,]
betaj0 <- ac.out.1e6$beta[j,]
zj0 <- ac.out.1e6$z[j,]
eta[j] <- etaj(betaj0, zj0, betaj2, zj2)
}
# Number of times chain is in the small set
sum(eta > 0)
pos_eta = eta[(eta > 0) == TRUE]
length(pos_eta)
sum=0
for (i in 1:length(pos_eta)) {
sum = sum + rbinom(1,1,pos_eta[i])
}
sum
COVARIANCE <- var(out.2e4$beta)
COVARIANCE
t(betaj2 - beta.bar)%*%solve(COVARIANCE)%*%(betaj2 - beta.bar)
set.seed(4321)
## Entering Data
x1.dummy <- seq(-3, 1.5, by = 0.5)
x2.dummy <- seq(0, 2, by = 0.5)
## The two column covariates
x1 <- rep(x1.dummy, each = length(x2.dummy))
x2 <- rep(x2.dummy, times = length(x1.dummy))
# Total number of cases. Follow the rows in the image above
n <- c(1, rep(0,4), 3, rep(0,4), 7, rep(0,3),
1, 6, 1, rep(0,3), 6,1,1,0,1,4,0,0,1,0,3,
0,1,1,0,4,0,1,1,1,1,0,1,1,4,1,0,0,2,0)
# Number of Lupus cases, foow the numerator across rows in the image
y <- c(0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,3,1,1,1,1,1,1,4,1,2)
# Following code makes a data matrix of all cases and lupus cases removing
# the combinations of covariates with noncases
dat.binom <- cbind(n,rep(1, 50), x1, x2)
dat.binom <- dat.binom[!(dat.binom[,1] == 0), ]
dat.binom <- cbind(dat.binom,y)
# Following code essentially converts binomial data to bernoulli data
dummy <- sapply(1:length(y), function(x) matrix(rep(dat.binom[x, -1], dat.binom[x,1]),nrow = dat.binom[x,1], byrow = TRUE) )
dat <- do.call(rbind, dummy)
dat[(dat[,4] >0),4] <- 1
# Fixing a mistake
dat[39,4] <- 0
colnames(dat) <- c("intercept", "x1", "x2", "y")
dim(dat)
x <- dat[, -4]
A =  t(x)%*%x
B = solve(A)
A = solve(B)
####################################################################################
####################################################################################
library(MASS)
library(Matrix)
library(truncnorm)
## AC for Bayesian probit regression
probit_gibbs <- function(dat, nsim)
{
# Separate covariates and response
x <- dat[, -4]
y <- dat[, 4]
m <- length(y)
#return objects
betas <- matrix(0, nrow = nsim, ncol = 3)
z <- matrix(0, nrow = nsim, ncol = m)
# starting value of beta are the mle estaimtes
z.curr <- numeric(length = m)
fit <- glm(y ~ -1 + x, family = binomial(link = "probit") )
beta.curr <- coef(fit)
# Needed for the truncated normal
lower <- numeric(length = m)
upper <- numeric(length = m)
for(i in 1:m)
{
if(y[i] == 0)
{
lower[i] <- -Inf
upper[i] <- 0
}else
{
lower[i] <- 0
upper[i] <- Inf
}
}
# Doing non-repetitive calculations outside
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
for(i in 1:nsim)
{
z.curr <- rtruncnorm(m, a = lower, b = upper, mean = x%*%beta.curr, sd = 1)
beta.curr <- inv.xtx %*% t(x) %*% z.curr + mvrnorm(n=1,c(0,0,0),inv.xtx)
betas[i, ] <- beta.curr
z[i, ] <- z.curr
}
return(list("beta" = betas, "z" = z))
}
###############################################################################
##Calculation of
init <- 2e4
out.2e4 <- probit_gibbs(dat = dat, nsim = init)
z.star <- colMeans(out.2e4$z[1:init, ])
beta.bar <- colMeans(out.2e4$beta[1:init, ])
s <- apply(out.2e4$beta[1:init, ], 2, sd)
c <- beta.bar - .09*s
d <- beta.bar + .09*s
COVARIANCE <- var(out.2e4$beta)
nsim <- 1e6
ac.out.1e6 <- probit_gibbs(dat = dat, nsim = nsim)
eta <- numeric(length = nsim)
x <- dat[, -4]
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
inv.xtx.tx <- solve(xtx)%*%t(x)
density_mv = function(input, mu, V){
lngt = length(input)
obj = exp(-0.5*t(input - mu)%*%solve(V)%*%(input - mu))/sqrt(det(V)*((2*pi)^(lngt)))
return(obj)
}
density_tn = function(inp, betaj){
for (t in 1:55) {
obj1 = 1
if(inp[t] > 0){
obj1 = obj1*dtruncnorm(inp[t], a = 0, b = Inf, mean = (x%*%betaj)[t], 1)
}else{
obj1 = obj1*dtruncnorm(inp[t], a = -Inf, b = 0, mean = (x%*%betaj)[t], 1)
}
}
return(obj1)
}
etaj <- function(betaj0, zj0, betaj2, zj2){
ret <- 0
t.starj <- t(zj0 - z.star)%*%x
if(t(betaj2 - beta.bar)%*%solve(COVARIANCE)%*%(betaj2 - beta.bar) < 10)
{
ret <- sum(t.starj*(c* (t.starj > 0) + d * (t.starj < 0))) - 0.5*t(zj0)%*%x%*%inv.xtx%*%t(x)%*%zj0 + 0.5*t(z.star)%*%x%*%inv.xtx%*%t(x)%*%z.star+ log(density_mv(betaj2,inv.xtx.tx%*%z.star,inv.xtx)) + sum(log(density_tn(zj2, betaj2)))
ret <- ret - log(density_mv(betaj2,inv.xtx.tx%*%zj0,inv.xtx) + density_mv(betaj2,inv.xtx.tx%*%zj0,inv.xtx)*prod(density_tn(zj2,betaj2)) +  density_mv(betaj2,inv.xtx.tx%*%zj2,inv.xtx)*prod(density_tn(zj2,betaj0)) + prod(density_tn(zj2,betaj0)))
ret <- exp(ret)
}else{
ret <- 0
}
return(ret)
}
for(j in 1:(nsim-2))
{
betaj2 <- ac.out.1e6$beta[j+2,]
zj2 <- ac.out.1e6$z[j+2,]
betaj0 <- ac.out.1e6$beta[j,]
zj0 <- ac.out.1e6$z[j,]
eta[j] <- etaj(betaj0, zj0, betaj2, zj2)
}
# Number of times chain is in the small set
sum(eta > 0)
pos_eta = eta[(eta > 0) == TRUE]
length(pos_eta)
sum=0
for (i in 1:length(pos_eta)) {
sum = sum + rbinom(1,1,pos_eta[i])
}
sum
s
#Number of total regenerations
sum=0
for (i in 1:length(eta)) {
sum = sum + rbinom(1,1,eta[i])
}
sum
getwd()
set.seed(4321)
library(MASS)
library(Matrix)
library(truncnorm)
## Entering Data
x1.dummy <- seq(-3, 1.5, by = 0.5)
x2.dummy <- seq(0, 2, by = 0.5)
## The two column covariates
x1 <- rep(x1.dummy, each = length(x2.dummy))
x2 <- rep(x2.dummy, times = length(x1.dummy))
# Total number of cases. Follow the rows in the image above
n <- c(1, rep(0,4), 3, rep(0,4), 7, rep(0,3),
1, 6, 1, rep(0,3), 6,1,1,0,1,4,0,0,1,0,3,
0,1,1,0,4,0,1,1,1,1,0,1,1,4,1,0,0,2,0)
# Number of Lupus cases, foow the numerator across rows in the image
y <- c(0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,3,1,1,1,1,1,1,4,1,2)
# Following code makes a data matrix of all cases and lupus cases removing
# the combinations of covariates with noncases
dat.binom <- cbind(n,rep(1, 50), x1, x2)
dat.binom <- dat.binom[!(dat.binom[,1] == 0), ]
dat.binom <- cbind(dat.binom,y)
# Following code essentially converts binomial data to bernoulli data
dummy <- sapply(1:length(y), function(x) matrix(rep(dat.binom[x, -1], dat.binom[x,1]),nrow = dat.binom[x,1], byrow = TRUE) )
dat <- do.call(rbind, dummy)
dat[(dat[,4] >0),4] <- 1
# Fixing a mistake
dat[39,4] <- 0
colnames(dat) <- c("intercept", "x1", "x2", "y")
dim(dat)
x <- dat[, -4]
A =  t(x)%*%x
B = solve(A)
A = solve(B)
####################################################################################
####################################################################################
## AC for Bayesian probit regression
probit_gibbs <- function(dat, nsim)
{
# Separate covariates and response
x <- dat[, -4]
y <- dat[, 4]
m <- length(y)
#return objects
betas <- matrix(0, nrow = nsim, ncol = 3)
z <- matrix(0, nrow = nsim, ncol = m)
# starting value of beta are the mle estaimtes
z.curr <- numeric(length = m)
fit <- glm(y ~ -1 + x, family = binomial(link = "probit") )
beta.curr <- coef(fit)
# Needed for the truncated normal
lower <- numeric(length = m)
upper <- numeric(length = m)
for(i in 1:m)
{
if(y[i] == 0)
{
lower[i] <- -Inf
upper[i] <- 0
}else
{
lower[i] <- 0
upper[i] <- Inf
}
}
# Doing non-repetitive calculations outside
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
inv.xtx_tx <- solve(xtx) %*% t(x)
errors <-  mvrnorm(n = nsim, c(0,0,0), inv.xtx)
for(i in 1:nsim)
{
z.curr <- rtruncnorm(m, a = lower, b = upper, mean = x%*%beta.curr, sd = 1)
beta.curr <- inv.xtx_tx %*% z.curr + errors[i, ]
betas[i, ] <- beta.curr
z[i, ] <- z.curr
}
return(list("beta" = betas, "z" = z))
}
###############################################################################
###############################################################################
##Calculation of D*
init <- 2e4
out.2e4 <- probit_gibbs(dat = dat, nsim = init)
z.star <- colMeans(out.2e4$z[1:init, ])
beta.bar <- colMeans(out.2e4$beta[1:init, ])
s <- apply(out.2e4$beta[1:init, ], 2, sd)
c <- beta.bar - .09*s
d <- beta.bar + .09*s
COVARIANCE <- var(out.2e4$beta)
#Generating samples from AC algorithm
nsim <- 1e6
ac.out.1e6 <- probit_gibbs(dat = dat, nsim = nsim)
#Non-repetative calculations
eta <- numeric(length = nsim)
x <- dat[, -4]
xtx <- t(x)%*%x
inv.xtx <- solve(xtx)
inv.xtx.tx <- solve(xtx)%*%t(x)
#Density for MV Normal
density_mv = function(input, mu, V){
lngt = length(input)
obj = exp(-0.5*t(input - mu)%*%solve(V)%*%(input - mu))/sqrt(det(V)*((2*pi)^(lngt)))
return(obj)
}
#Density for Truncated Normal
density_tn = function(inp, betaj){
for (t in 1:55) {
obj1 = 1
if(inp[t] > 0){
obj1 = obj1*dtruncnorm(inp[t], a = 0, b = Inf, mean = (x%*%betaj)[t], 1)
}else{
obj1 = obj1*dtruncnorm(inp[t], a = -Inf, b = 0, mean = (x%*%betaj)[t], 1)
}
}
return(obj1)
}
save(nsim, init, out.2e4, z.star, beta.bar, s, c, d, COVARIANCE, ac.out.1e6, xtx, inv.xtx, inv.xtx.tx, density_mv, density_tn, file = "Regen_func.RData")
set.seed(4321)
library(MASS)
library(Matrix)
library(truncnorm)
load("Regen_func.RData")
pdf(file="Rplot.pdf")
#ACF of beta samples from AC
par(mfrow = c(1,3))
acf(ac.out.1e6$beta[,1], ylim = c(0.85,1), main = expression(paste("AC for ", beta(1))))
acf(ac.out.1e6$beta[,2], ylim = c(0.85,1), main = expression(paste("AC for ", beta(2))))
acf(ac.out.1e6$beta[,3], ylim = c(0.85,1), main = expression(paste("AC for ", beta(3))))
dev.off()
